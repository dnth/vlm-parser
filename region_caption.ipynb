{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-01 21:40:57.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mModel: microsoft/Florence-2-large-ft\u001b[0m\n",
      "\u001b[32m2025-01-01 21:40:57.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mDevice: cuda\u001b[0m\n",
      "\u001b[32m2025-01-01 21:40:57.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mDtype: float16\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bboxes': [[425.2799987792969,\n",
       "   238.95750427246094,\n",
       "   502.7200012207031,\n",
       "   289.6935119628906],\n",
       "  [48.31999969482422,\n",
       "   254.35951232910156,\n",
       "   130.87998962402344,\n",
       "   301.47149658203125],\n",
       "  [152.63999938964844,\n",
       "   251.18850708007812,\n",
       "   226.87998962402344,\n",
       "   300.1125183105469],\n",
       "  [493.7599792480469,\n",
       "   239.86351013183594,\n",
       "   564.1599731445312,\n",
       "   288.3345031738281],\n",
       "  [74.55999755859375,\n",
       "   241.67550659179688,\n",
       "   95.68000030517578,\n",
       "   286.06951904296875],\n",
       "  [174.39999389648438,\n",
       "   238.05149841308594,\n",
       "   191.67999267578125,\n",
       "   283.80450439453125],\n",
       "  [449.5999755859375,\n",
       "   224.9145050048828,\n",
       "   466.8799743652344,\n",
       "   265.23150634765625],\n",
       "  [521.2799682617188, 229.4445037841797, 533.4400024414062, 278.3684997558594],\n",
       "  [83.5199966430664,\n",
       "   216.30751037597656,\n",
       "   101.43999481201172,\n",
       "   243.9405059814453]],\n",
       " 'labels': ['horse',\n",
       "  'horse',\n",
       "  'horse',\n",
       "  'horse',\n",
       "  'person',\n",
       "  'person',\n",
       "  'person',\n",
       "  'person',\n",
       "  'person']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xinfer\n",
    "\n",
    "model = xinfer.create_model(\"microsoft/Florence-2-large-ft\", device=\"cuda\", dtype=\"float16\")\n",
    "\n",
    "image_path = \"/home/dnth/Desktop/pgsql-search/data/images/53120.jpg\"\n",
    "\n",
    "results = model.infer(image_path, text=\"<DENSE_REGION_CAPTION>\").text\n",
    "\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
